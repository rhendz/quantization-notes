{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "\n",
    "# Load the Fashion MNIST dataset\n",
    "fashion_mnist_train = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "# Create a dataloader for the training\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    fashion_mnist_train, batch_size=10, shuffle=True\n",
    ")\n",
    "\n",
    "# Load the Fashion MNIST test set\n",
    "fashion_mnist_test = datasets.FashionMNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    fashion_mnist_test, batch_size=10, shuffle=True\n",
    ")\n",
    "\n",
    "# Define the device\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMNISTNet, self).__init__()\n",
    "        # First convolutional layer\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        # Second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)  # Output layer with 10 classes for Fashion MNIST\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through first convolutional layer\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # Max pooling\n",
    "        x = self.pool(x)\n",
    "        # Forward pass through second convolutional layer\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # Max pooling\n",
    "        x = self.pool(x)\n",
    "        # Flatten the tensor for fully connected layers\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        # Forward pass through fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FashionMNISTNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 6000/6000 [00:16<00:00, 357.96it/s, loss=0.353]\n"
     ]
    }
   ],
   "source": [
    "def train(train_loader, net, epochs=5, total_iterations_limit=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net.to(device)\n",
    "\n",
    "    cross_el = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    total_iterations = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "\n",
    "        loss_sum = 0\n",
    "        num_iterations = 0\n",
    "\n",
    "        data_iterator = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "        if total_iterations_limit is not None:\n",
    "            data_iterator.total = total_iterations_limit\n",
    "        for data in data_iterator:\n",
    "            num_iterations += 1\n",
    "            total_iterations += 1\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = net(x)\n",
    "            loss = cross_el(output, y)\n",
    "            loss_sum += loss.item()\n",
    "            avg_loss = loss_sum / num_iterations\n",
    "            data_iterator.set_postfix(loss=avg_loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (\n",
    "                total_iterations_limit is not None\n",
    "                and total_iterations >= total_iterations_limit\n",
    "            ):\n",
    "                return\n",
    "\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
    "    print(\"Size (KB):\", os.path.getsize(\"temp_delme.p\") / 1e3)\n",
    "    os.remove(\"temp_delme.p\")\n",
    "\n",
    "\n",
    "MODEL_FILENAME = \"simplenet_ptq.pt\"\n",
    "\n",
    "if Path(MODEL_FILENAME).exists():\n",
    "    net.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "    print(\"Loaded model from disk\")\n",
    "else:\n",
    "    train(train_loader, net, epochs=1)\n",
    "    # Save the model to disk\n",
    "    torch.save(net.state_dict(), MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the testing loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation during inference\n",
    "        data_iterator = tqdm(test_loader, desc=\"Testing\")\n",
    "        for data in data_iterator:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            accuracy = 100 * correct / total\n",
    "            data_iterator.set_postfix(accuracy=accuracy)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(\"Accuracy on test set: {:.2f}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print weights and size of the model before quantization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights before quantization\n",
      "Parameter containing:\n",
      "tensor([[[[-0.2513, -0.1076, -0.0871],\n",
      "          [-0.1587, -0.4168, -0.1259],\n",
      "          [ 0.0252,  0.1552,  0.2302]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2138,  0.1370, -0.0802],\n",
      "          [ 0.2687, -0.2193, -0.2469],\n",
      "          [ 0.0560, -0.2383,  0.1258]]],\n",
      "\n",
      "\n",
      "        [[[-0.1809, -0.1614,  0.0100],\n",
      "          [-0.0992, -0.0296, -0.1993],\n",
      "          [-0.3367, -0.3854, -0.0999]]],\n",
      "\n",
      "\n",
      "        [[[-0.3667, -0.4436, -0.3355],\n",
      "          [-0.0392, -0.2447,  0.2916],\n",
      "          [ 0.0837,  0.1865,  0.1145]]],\n",
      "\n",
      "\n",
      "        [[[-0.3207,  0.3156, -0.1251],\n",
      "          [ 0.2831,  0.0210, -0.3048],\n",
      "          [-0.1081,  0.2689, -0.2202]]],\n",
      "\n",
      "\n",
      "        [[[-0.3246, -0.0110,  0.3484],\n",
      "          [-0.3568,  0.3324, -0.0680],\n",
      "          [-0.2925,  0.3689,  0.0460]]],\n",
      "\n",
      "\n",
      "        [[[-0.3064,  0.2084,  0.2716],\n",
      "          [ 0.2391, -0.3100,  0.1197],\n",
      "          [ 0.3175, -0.0753, -0.2631]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0092,  0.0445,  0.2723],\n",
      "          [-0.3734, -0.0521,  0.3880],\n",
      "          [-0.2184, -0.2605,  0.4127]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2473, -0.1068,  0.0039],\n",
      "          [-0.2246, -0.3320, -0.3678],\n",
      "          [ 0.3055,  0.0952, -0.1670]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1569,  0.2196, -0.4039],\n",
      "          [ 0.1818, -0.0680, -0.4281],\n",
      "          [-0.1444, -0.1163, -0.3644]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1198, -0.2004,  0.1837],\n",
      "          [-0.3260,  0.0614, -0.0911],\n",
      "          [ 0.2030, -0.2051,  0.0170]]],\n",
      "\n",
      "\n",
      "        [[[-0.1835,  0.2840,  0.0051],\n",
      "          [-0.0064, -0.3189, -0.1469],\n",
      "          [-0.3451, -0.2146, -0.3658]]],\n",
      "\n",
      "\n",
      "        [[[-0.0612,  0.1292, -0.0598],\n",
      "          [-0.3907, -0.3457,  0.1064],\n",
      "          [-0.0670, -0.0516,  0.1332]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0858,  0.2103, -0.2074],\n",
      "          [-0.3731, -0.0397,  0.3295],\n",
      "          [-0.2718, -0.2224, -0.2029]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0390, -0.2610,  0.2485],\n",
      "          [ 0.4175, -0.3301, -0.0917],\n",
      "          [ 0.3543, -0.0718, -0.2850]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2830, -0.1656, -0.2443],\n",
      "          [-0.3077,  0.2331,  0.2135],\n",
      "          [-0.0569, -0.1299, -0.0427]]],\n",
      "\n",
      "\n",
      "        [[[-0.1319, -0.1657, -0.3150],\n",
      "          [-0.2562, -0.4553,  0.1193],\n",
      "          [ 0.2548,  0.2324, -0.0973]]],\n",
      "\n",
      "\n",
      "        [[[-0.2184, -0.2516, -0.3309],\n",
      "          [ 0.1839, -0.1927, -0.0640],\n",
      "          [ 0.1734, -0.2290, -0.1979]]],\n",
      "\n",
      "\n",
      "        [[[-0.2807, -0.1755,  0.1756],\n",
      "          [-0.1666, -0.2468, -0.1178],\n",
      "          [-0.4494, -0.2971,  0.1648]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0242,  0.0651, -0.3845],\n",
      "          [ 0.0974,  0.2075, -0.1756],\n",
      "          [ 0.1493,  0.1217,  0.2467]]],\n",
      "\n",
      "\n",
      "        [[[-0.0861, -0.3417, -0.1858],\n",
      "          [ 0.2409, -0.0817,  0.0354],\n",
      "          [ 0.2251,  0.0048, -0.0152]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1598,  0.2598, -0.1429],\n",
      "          [ 0.1982,  0.1512, -0.1413],\n",
      "          [-0.2429, -0.0861, -0.3345]]],\n",
      "\n",
      "\n",
      "        [[[-0.3538,  0.2989,  0.0602],\n",
      "          [ 0.2276,  0.2075, -0.0505],\n",
      "          [ 0.1438,  0.1817, -0.2936]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0560,  0.1123, -0.0653],\n",
      "          [ 0.3644,  0.0175,  0.0685],\n",
      "          [-0.4758, -0.5949, -0.2687]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2846, -0.2619,  0.3227],\n",
      "          [ 0.1959, -0.1728, -0.2239],\n",
      "          [-0.3939, -0.6172, -0.4713]]],\n",
      "\n",
      "\n",
      "        [[[-0.1812, -0.2776,  0.3904],\n",
      "          [ 0.0080, -0.0460,  0.0819],\n",
      "          [ 0.3359, -0.1686, -0.2443]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0143,  0.1489,  0.1306],\n",
      "          [ 0.0583, -0.2014,  0.2787],\n",
      "          [ 0.1849,  0.0691, -0.2588]]],\n",
      "\n",
      "\n",
      "        [[[-0.1866,  0.3130, -0.0949],\n",
      "          [-0.3317,  0.1926,  0.1706],\n",
      "          [ 0.0056, -0.2374,  0.2117]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2108, -0.3420,  0.0242],\n",
      "          [ 0.1776, -0.1346,  0.0902],\n",
      "          [-0.2875,  0.1848,  0.0164]]],\n",
      "\n",
      "\n",
      "        [[[-0.4059,  0.0122, -0.3492],\n",
      "          [ 0.1861, -0.4418, -0.3107],\n",
      "          [ 0.2885, -0.1836, -0.1427]]],\n",
      "\n",
      "\n",
      "        [[[-0.3480,  0.0013, -0.3237],\n",
      "          [-0.4497, -0.3242,  0.2994],\n",
      "          [-0.2346,  0.0752,  0.1273]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1379, -0.1438,  0.0542],\n",
      "          [-0.0176,  0.3489, -0.3514],\n",
      "          [-0.1095,  0.3106, -0.2061]]]], device='cuda:0', requires_grad=True)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Print the weights matrix of the model before quantization\n",
    "print(\"Weights before quantization\")\n",
    "print(net.conv1.weight)\n",
    "print(net.conv1.weight.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model before quantization\n",
      "Size (KB): 1689.828\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the model before quantization\")\n",
    "print_size_of_model(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model before quantization: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:01<00:00, 590.94it/s, accuracy=88.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 88.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model before quantization: \")\n",
    "test(test_loader, net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
